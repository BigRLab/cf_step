{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> Algorithm assessment metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall@k\n",
    "\n",
    "Recall@k is a standard information retrieval metric. For example, suppose that we computed *recall@10* equal to 40% in our top-10 recommendation system. This means that 40% of the total number of the relevant items appear in the top-k results.\n",
    "\n",
    "More formally we have:\n",
    "\n",
    "$$Recall@k = \\frac{\\text{number of recommended items @k that are relevant}}{\\text{total number of relevant items}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def recall_at_k(predictions: List[int], targets: List[int], k: int = 10) -> float:\n",
    "    \"\"\"Computes `Recall@k` from the given predictions and targets sets.\"\"\"\n",
    "    predictions_set = set(predictions[:k])\n",
    "    targets_set = set(targets)\n",
    "    result = len(targets_set & predictions_set) / float(len(targets_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments:\n",
    "\n",
    "* predictions (list[int]): The list of recommended items\n",
    "* targets (list[int]): The list of relevant items\n",
    "* k (int): The number up to where the recall is computed - default: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (5, 6, 32, 67, 1, 15, 7, 89, 10, 43)\n",
    "targets = (15, 5, 44, 35, 67, 101, 7, 80, 43, 12)\n",
    "\n",
    "assert recall_at_k(predictions, targets, 5) == .2, 'Recall@k should be equal to 2/10 = 0.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@k\n",
    "\n",
    "Precision@k is a standard information retrieval metric. For example, an interpretation of precision@k computed at 80% could be that that 80% of the total number of the recommendations made are relevant to the user.\n",
    "\n",
    "More formally we have:\n",
    "\n",
    "$$Precision@k = \\frac{\\text{number of recommended items @k that are relevant}}{\\text{number of recommended items @k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def precision_at_k(predictions: List[int], targets: List[int], k: int = 10) -> float:\n",
    "    \"\"\"Computes `Precision@k` from the given predictions and targets sets.\"\"\"\n",
    "    predictions_set = set(predictions[:k])\n",
    "    targets_set = set(targets)\n",
    "    result = len(targets_set & predictions_set) / float(len(predictions_set))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguments:\n",
    "\n",
    "* predictions (list[int]): The list of recommended items\n",
    "* targets (list[int]): The list of relevant items\n",
    "* k (int): The number up to where the recall is computed - default: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (5, 6, 32, 67, 1, 15, 7, 89, 10, 43)\n",
    "targets = (15, 5, 44, 35, 67, 101, 7, 80, 43, 12)\n",
    "\n",
    "assert precision_at_k(predictions, targets, 5) == .4, 'Recall@k should be equal to 2/5 = 0.4'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cfstep]",
   "language": "python",
   "name": "conda-env-cfstep-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
